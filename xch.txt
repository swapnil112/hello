import torch
import transformers

class ClinicalBERTEmbedding(torch.nn.Module):
    def __init__(self):
        super(ClinicalBERTEmbedding, self).__init__()
        self.tokenizer = transformers.ClinicalBertTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')
        self.model = transformers.ClinicalBertModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')

    def forward(self, text):
        input_ids = torch.tensor(self.tokenizer.encode(text, add_special_tokens=True)).unsqueeze(0)
        outputs = self.model(input_ids)
        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze()
        return embeddings

model = ClinicalBERTEmbedding()
text = "The patient presented with shortness of breath and chest pain."
embedding = model(text)
print(embedding)
